{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Simulation of Denoising Methodologies\n",
    "\n",
    "In this notebook we compare three empirical Bayes denoising methods on a simulated data set, and we create Figure 1.1 from the arxiv version of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from npeb.GLMixture import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "import scipy.stats as stats\n",
    "from scipy.linalg import sqrtm, inv\n",
    "from scipy.spatial import distance_matrix\n",
    "import ot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data\n",
    "\n",
    "We sample the latent variables $\\Theta_1,\\ldots,\\Theta_n$ from a distribution $G$ which is two-component Gaussian mixture model in $\\mathbb{R}^2$, with component centers $c_1 = (0.5, 0.5)^{\\top}$ and $c_2 = (-0.5, -0.5)^{\\top}$ and component variance $\\tau^2I_2$ for $\\tau^2 = 0.1$. Then, we sample the observations from a Gaussian likelihood with variance $\\sigma^2I_2$ for $\\sigma^2 = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "n = 2500\n",
    "center1 = np.asarray([0.5, 0.5])\n",
    "center2 = np.asarray([-0.5, -0.5])\n",
    "tau2 = 0.1\n",
    "sigma2 = 1.0\n",
    "\n",
    "np.random.seed(54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sampling the latent variables\n",
    "\n",
    "centers = np.vstack([center1,center2])\n",
    "\n",
    "def sample_latent(nsamples,var):\n",
    "    classes = np.random.randint(0,2,size=nsamples)\n",
    "    indices = np.zeros((nsamples,2))\n",
    "    indices[np.arange(nsamples),classes] = 1\n",
    "    Theta = np.random.normal(indices@centers,np.sqrt(var))\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the latent variables and the observations\n",
    "\n",
    "Theta =  sample_latent(n,tau2)\n",
    "prec = np.ones_like(Theta)/sigma2\n",
    "prec_smooth = 1./(1./prec + tau2)\n",
    "Z = np.random.normal(Theta,np.sqrt(sigma2),size=(n,2))\n",
    "L = np.max(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute denoisers\n",
    "\n",
    "Next, we compute the three denoisers of interest (at both the oracle and empirical levels) for the data above. We do this with the help of the `npeb` package above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Unconstrained) oracle Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_model = GLMixture(prec_type='diagonal')\n",
    "n_supp = 10000\n",
    "supp = sample_latent(n_supp,tau2)\n",
    "ob_model.set_params(atoms=supp, weights=np.ones(n_supp)/n_supp)\n",
    "ob = ob_model.posterior_mean(Z, prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Unconstrained) empirical Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all data points as atoms: done.\n",
      "Computing kernel matrix: done.\n",
      "Solving for discretized NPMLE: done.\n",
      "Running EM: done.                 \r"
     ]
    }
   ],
   "source": [
    "eb_model = GLMixture(prec_type='diagonal')\n",
    "eb_model.fit(Z, prec)\n",
    "\n",
    "eb_post_means = eb_model.posterior_mean(Z, 1./(1./prec + tau2))\n",
    "eb = tau2 * Z / (tau2 + 1./prec) + (1./prec) * eb_post_means / (tau2 + 1./prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle variance-constrained Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.cov(ob.T)\n",
    "A = np.cov(Theta.T)\n",
    "transport = inv(sqrtm(M))@sqrtm(sqrtm(M)@A@sqrtm(M))@inv(sqrtm(M))\n",
    "ovcb = ob@transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical variance-constrained Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.mean(eb,axis=0)\n",
    "M_hat = (eb-c).T@(eb-c)/n\n",
    "\n",
    "mu_hat = np.mean(Z,axis=0)\n",
    "A_hat = (Z-mu_hat).T@(Z-mu_hat)/n - sigma2*np.eye(2)\n",
    "\n",
    "transport_hat = inv(sqrtm(M_hat))@sqrtm(sqrtm(M_hat)@A_hat@sqrtm(M_hat))@inv(sqrtm(M_hat))\n",
    "\n",
    "evcb = (eb - mu_hat)@transport_hat + mu_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle distribution-constrained Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aqjaffe/opt/anaconda3/lib/python3.9/site-packages/ot/lp/__init__.py:388: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  result_code_string = check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "k = 300\n",
    "Eta_x = np.linspace(-1.5,1.5,k)\n",
    "Eta_y = np.linspace(-1.5,1.5,k)\n",
    "Eta = np.array(list(itertools.product(Eta_x,Eta_y)))\n",
    "\n",
    "Eta_wt = np.zeros(k**2)\n",
    "for i in range(n):\n",
    "    rv = stats.multivariate_normal(mean=Theta[i,:], cov=[tau2, tau2])\n",
    "    probs = rv.pdf(Eta)\n",
    "    Eta_wt += probs / (n*np.sum(probs))\n",
    "Eta_wt = Eta_wt/np.sum(Eta_wt)\n",
    "\n",
    "C_hat = distance_matrix(ob, Eta)**2\n",
    "pi = ot.emd(np.ones(n)/n, Eta_wt, C_hat, numItermax=1e6)\n",
    "\n",
    "odcb = np.zeros((n,2))\n",
    "for i in range(n):\n",
    "    odcb[i,:] = (pi[i,:].reshape(1,-1)@Eta)/np.sum(pi[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical distribution-constrained Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eta_wt = np.zeros(k**2)\n",
    "at, wt = eb_model.get_params()\n",
    "m = len(wt)\n",
    "for i in range(m):\n",
    "    rv = stats.multivariate_normal(mean=at[i,:], cov=[tau2, tau2])\n",
    "    probs = rv.pdf(Eta)\n",
    "    Eta_wt += probs * wt[i] / np.sum(probs)\n",
    "Eta_wt = Eta_wt/np.sum(Eta_wt)\n",
    "\n",
    "C_hat = distance_matrix(eb, Eta)**2\n",
    "pi = ot.emd(np.ones(n)/n, Eta_wt, C_hat, numItermax=1e6)\n",
    "\n",
    "edcb = np.zeros((n,2))\n",
    "for i in range(n):\n",
    "    edcb[i,:] = (pi[i,:].reshape(1,-1)@Eta)/np.sum(pi[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Lastly, we plot the latent variables and the observations, along with the three denoising methods of interest, at both the oracle and empirical levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22,\n",
    "                     'mathtext.fontset': 'stix',\n",
    "                     'font.family': 'serif',\n",
    "                     'font.serif':'Palatino'})\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(16,8.5))\n",
    "Z_alpha = 0.75\n",
    "Z_s = 1.0\n",
    "G_alpha = 0.5\n",
    "\n",
    "# top row\n",
    "\n",
    "ax[0,0].set_title('$\\\\Theta_i$')\n",
    "ax[0,0].scatter(Theta[:,0], Theta[:,1], s=Z_s,color='blue', alpha=Z_alpha)\n",
    "    \n",
    "ax[0,1].set_title('$\\\\delta_{\\\\mathcal{B}}(Z_i)$')\n",
    "ax[0,1].scatter(ob[:,0], ob[:,1], s=Z_s,color='black', alpha=Z_alpha)\n",
    "\n",
    "ax[0,2].set_title('$\\\\delta_{\\\\mathcal{VCB}}(Z_i)$')\n",
    "ax[0,2].scatter(ovcb[:,0], ovcb[:,1], s=Z_s,color='black', alpha=Z_alpha)\n",
    "\n",
    "ax[0,3].set_title('$\\\\delta_{\\\\mathcal{DCB}}(Z_i)$')\n",
    "ax[0,3].scatter(odcb[:,0], odcb[:,1], s=Z_s,color='black', alpha=Z_alpha)\n",
    "\n",
    "# bottom row\n",
    "\n",
    "ax[1,0].set_title('$Z_i$')\n",
    "ax[1,0].scatter(Z[:,0], Z[:,1], s=Z_s,color='black', alpha=Z_alpha)\n",
    "\n",
    "ax[1,1].set_title('$\\\\hat{\\\\delta}_{\\\\mathcal{B}}(Z_i)$')\n",
    "ax[1,1].scatter(eb[:,0], eb[:,1], s=Z_s,color='black', alpha=Z_alpha)\n",
    "\n",
    "ax[1,2].set_title('$\\\\hat{\\\\delta}_{\\\\mathcal{VCB}}(Z_i)$')\n",
    "ax[1,2].scatter(evcb[:,0], evcb[:,1], s=Z_s,color='black', alpha=Z_alpha)\n",
    "\n",
    "ax[1,3].set_title('$\\\\hat{\\\\delta}_{\\\\mathcal{DCB}}(Z_i)$')\n",
    "ax[1,3].scatter(edcb[:,0], edcb[:,1], s=Z_s,color='black', alpha=Z_alpha)\n",
    "\n",
    "u = np.linspace(0,2*np.pi)\n",
    "circ1 = center1 + 2*np.sqrt(tau2)*np.vstack([np.sin(u),np.cos(u)]).T\n",
    "circ2 = center2 + 2*np.sqrt(tau2)*np.vstack([np.sin(u),np.cos(u)]).T\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        # if i > 0 or j > 0:\n",
    "        ax[i,j].plot(circ1[:,0],circ1[:,1],color='blue',linestyle='dashed', alpha=0.75)\n",
    "        ax[i,j].plot(circ2[:,0],circ2[:,1],color='blue',linestyle='dashed', alpha=0.75)\n",
    "            # ax[i,j].scatter(Theta[:,0], Theta[:,1], s=Z_s,color='blue', alpha=G_alpha)\n",
    "\n",
    "plt.xlim([-1.25,1.25])\n",
    "plt.ylim([-1.25, 1.25])\n",
    "plt.tight_layout()\n",
    "plt.savefig('BasicSimulation.pdf')\n",
    "plt.savefig('BasicSimulation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
